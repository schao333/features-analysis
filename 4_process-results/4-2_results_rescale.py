#!/usr/bin/env python3
# -*- coding: utf-8 -*-


###############################################################################
# RESCALE MODEL RESULTS
# and create graph
# 4-2_results_rescale.py

# Created by: Steven Chao
# Fall 2020
# The George Washington University

# This script unscales the scaled predicted and actual values generated by
# the model building to make the model results more interpretable. First, the
# code unscales the data and compares the newly unscaled data with the
# unscaled data that was created before the model building (these datasets
# should be pretty much equal). Then, the code creates, exports, and saves
# graphs of the unscaled predicted vs. actual values.
# The code iterates through each dependent variable, dependent variable type,
# and model building metod.

# Input files should have the same primary key. Input files required include:
# the original CSV with the scaled and unscaled dependent variable (y_values),
# and the predicted vs. actual CSV generated by the model.

# * Change as necessary
# """text""" Replace placeholder text with relevant text
###############################################################################


# Import modules
import pandas as pd
from sklearn import preprocessing
import os
import glob
import matplotlib.pyplot as plt


def unscale_data(method, dep_var_type, dep_var, area):
    '''The code unscales the data and compares the newly unscaled data with
    the unscaled data that was created before the model building. Then, the
    code creates, exports, and saves graphs of the unscaled predicted vs.
    actual values.'''
    
    # Create key that will be used to create dataframe index
    key = "FIPS"
    
    print("Reading CSV for {}, {} ({}), {}...".format(method, dep_var_type, dep_var, area))
    
    # Get CSV file that has scaled and unscaled dependent variable
    y_values = pd.read_csv(glob.glob(os.path.join(base_folder, dep_var_type, "{}_{}_y-values.csv".format(area, dep_var)))[0])
    
    # Set index of dataframe to FIPS
    y_values = y_values.set_index(key)
    
    # Create new dataframe holding unscaled dependent variable
    unscaled_y = pd.DataFrame(y_values["{}_unscaled".format(dep_var)])
    
    # Create new dataframe holding original scaled dependent variable
    original_scaled = pd.DataFrame(y_values["{}_scaled".format(dep_var)])
    
    # Scale the data
    print("Standardizing data...")
    standard_scaler = preprocessing.StandardScaler()
    scaled_y = standard_scaler.fit_transform(unscaled_y)
    scaled_y = pd.DataFrame(scaled_y, index = y_values.index, columns = ["{}_scaled".format(dep_var)]) 
    
    print("Checking scaled data...")
    # Check if newly scaled data matches the originally scaled data
    # Data rounded to 10 decimals to ignore any minor changes in
    # values/rounding issues
    if scaled_y.round(10).equals(original_scaled.round(10)):
        pass
        
    # Raise error if they do not match
    # If no match, try changing the rounding value
    else:
        raise Exception("The newly unscaled data does not match the original unscaled data. Please check the datasets.")
    
    # Get all the predicted vs. actual datasets, and iterate through each
    # seed's dataset, unscaling the data and creating a graph
    for csv_file in glob.glob(os.path.join(base_folder, dep_var_type, method, "{}_{}_{}_*_pred-act.csv".format(area, method, dep_var))):
        # Read in CSV and set the index
        predicted_actual = pd.read_csv(csv_file)
        predicted_actual = predicted_actual.set_index(key)
        
        # Split the file path into the head (everything before the filename),
        # root (the filename without the extention), and the extension
        head, tail = os.path.split(csv_file)
        root, ext = os.path.splitext(tail)
        
        print("\nUnscaling {}...".format(tail))
        
        # Create a new dataframe with the predicted and actual data to
        # be unscaled
        scaled_pred_act = predicted_actual[["actual", "predicted"]]
        
        # Unscale the data, and create a new dataframe with the unscaled data
        unscaled_pred_act = pd.DataFrame(standard_scaler.inverse_transform(scaled_pred_act), index = scaled_pred_act.index, columns = scaled_pred_act.columns)
        
        # Delete the scaled predicted and actual data in the original dataframe
        predicted_actual = predicted_actual.drop(scaled_pred_act.columns, axis = 1)
        
        # Replace this deleted data with the unscaled predicted and actual data
        predicted_actual = pd.concat([predicted_actual, unscaled_pred_act], axis = 1)
        
        # Export dataframe to CSV
        predicted_actual.to_csv(os.path.join(head, "{}-rescaled{}".format(root, ext)))
        
        # Group dataframe by area
        groups = predicted_actual.groupby("area")
        
        # Create plot
        print("Creating graph for {}...".format(tail))
        fig, ax = plt.subplots(figsize = (15, 10))
    
        # Add 5% padding to autoscaling
        ax.margins(0.05)
    
        # Iterate through each group and plot points
        for name, group in groups:
            ax.plot(group.actual, group.predicted, marker='o', linestyle='', ms=3, label=name)
        
        # Create a legend
        ax.legend()
    
        # Create and save the figure
        plt.savefig(os.path.join(head, "{}-fig-rescaled.png".format(root)), dpi = 300, format = "png")
        plt.show()
        plt.close()
        
    print("\n\n")



# Set the base folder that contains the scaled data and the model results
# (model results should be in subfolder) *
base_folder = r"""/regressions"""

# Iterate through each model building method *
for method in ["""enr""", """rfr"""]:
    
    # Iterate through each dependent variable type *
    for dep_var_type in ["""pop""", """osm"""]:
        
        # Check user input of dependent variable type
        if dep_var_type.lower() == "pop":
            
            # Choose population variable names
            dep_var_list = ["pop_density_km"]
            
        elif dep_var_type.upper() == "OSM":
            
            # Choose OSM variable names
            dep_var_list = ["BUILD_DEN", "BUILTUP_AREA", "BUILTUP_DEN_PRCNT", "COUNT_BUILD", "RD_AREA", "RD_DEN", "RD_LENGTH", "SUM_BUILD_AREA"]
        
        else:
            
            # Raise error if dependent variable not specified
            raise Exception("Specify the dependent variable!")
        
        # Iterate through each dependent variable
        for dep_var in dep_var_list:
        
            # Iterate through each area *
            for area in ["""sl""", """blz""", """gh""", """sl-blz-gh"""]:
                
                # Run the function
                unscale_data(method = method, dep_var_type = dep_var_type, dep_var = dep_var, area = area)


print("Done.")